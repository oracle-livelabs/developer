# Mixed Reality and Vision AI For Hearing And Vision Impaired And Alzheimer’s

## Introduction

This lab will show you how to use Oracle AI Database, Vision AI, Gen AI, and Mixed Reality. 
The use cases involve the names of objects in a person's surroundings being spoken out to them from the spatial location where they are located for individuals that are hearing impaired or have Alzheimer’s as well as summarizations, etc. of text found within the user's view.

Estimated Time:  10 minutes

[](youtube:40ADd-ALkcc)

[](youtube:QTe2trT2ZHM)

### Objectives

-   Use Oracle AI Database, OCI Vision AI, Open AI, and Mixed Reality

### Prerequisites

- Completion of Setup lab

## Task 1: Deploy and run the application on Mixed Reality headset as the frontend and using Spring Boot, Oracle AI and Database services as the backend.

Full details of how to deploy and run this application can be found here: https://blogs.oracle.com/developers/post/develop-xr-with-oracle-ep-6-content-summarizer-generator-using-database-vision-ai-cohere-hugging-face-and-open-ai

The backend has already been set up by this workshop and all remaining work is related to the MR frontend. 

You may now **proceed to the next lab.**..

## Acknowledgements

* **Author** - Paul Parkinson, Architect and Developer Advocate
* **Last Updated By/Date** - Paul Parkinson, 2024
